---
title: "shorts: An R Package for Modeling Short Sprints"
date: "`r Sys.Date()`"
author: 
  - Mladen JovanoviÄ‡^[Faculty of Sport and Physical Education, University of Belgrade, Serbia, coach.mladen.jovanovic@gmail.com]
  - Jason D. Vescovi^[Faculty of Kinesiology and Physical Education, Graduate School of Exercise Science, Toronto, ON Canada, vescovij@gmail.com]
abstract: >
  Short sprint performance is one of the most distinguishable and admired physical traits in sports. Short sprints have been modeled using the mono-exponential equation that involves two parameters: (1) maximum sprinting speed (MSS) and (2) relative acceleration (TAU). The most common methods to assess short sprint performance are with a radar gun or timing gates. In this paper, we: 1) provide the **shorts** package that can model sprint timing data from these two sources; 2) discuss potential issues with assessing sprint time (synchronization and flying start, respectively); and 3) provide model definitions within the **shorts** package to help alleviate errors within the subsequent parameter outcomes.
citation_package: natbib
bibliography: [references.bib, packages.bib]
output:
  bookdown::word_document2:
    number_sections: FALSE
link-citations: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
require(knitr)
require(shorts)
require(tidyverse)
require(bookdown)

my_random_seed <- 1667
set.seed(my_random_seed)

def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  cache = FALSE,
  fig.retina = 0.8, # figures are either vectors or 300 dpi diagrams
  dpi = 600,
  out.width = "90%",
  fig.align = "center",
  fig.width = 5,
  fig.height = 5 * 0.618, # 1 / phi
  fig.show = "hold",
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  width = 65,
  size = "small"
)

# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), "bookdown", "knitr", "rmarkdown", "shorts", "nlme", "LambertW", "kableExtra"
 ), "packages.bib")


# Set rounding
op <- options()

options(
  digits = 3,
  "width" = 65,
  scipen = 999
)
```

# Introduction

Short sprint performance is one of the most distinguishable and admired physical traits in sports. Short sprints, commonly performed in most team sports (e.g., soccer, field hockey, handball, football, etc.), are defined as maximal running from a stand still position over a distance that doesn't result in deceleration at the end. Peak anaerobic power is achieved within the first few seconds (<5 s) of maximal efforts [@mangineSpeedForcePower2014], whereas the ability to achieve maximal sprint speed varies based on the athlete and their sport. For example, track and field sprinters are trained to achieve maximal speed later in a race (i.e., 50-60 m) [@ward-smithEnergyConversionStrategies2001], but team sport athletes have sport-specific attributes and reach it much sooner (i.e., 30-40 m)[@brownAssessmentLinearSprinting2004]. Regardless of the differences in kinematics between athletes, evaluating short sprint performance is routinely included within a battery of fitness tests for a wide range of sports

The use of force plates is considered the gold standard for assessing mechanical properties of sprinting; however, there are logistical and financial challenges to capturing the profile of an entire sprint [@morinSimpleMethodComputing2019; @samozinoSimpleMethodMeasuring2016]. Radar and laser technology are frequently used laboratory-grade methods [@buchheitMechanicalDeterminantsAcceleration2014; @edwardsSprintAccelerationCharacteristics2020; @jimenez-reyesRelationshipVerticalHorizontal2018; @marcote-pequenoAssociationForceVelocity2019] but not normally accessible to practitioners working in sports. Undoubtedly, the most common method available and used to evaluate sprint performance are timing gates. Often multiple gates are positioned at varying distances to capture split times (e.g., 5, 10, 20 m), which can now be incorporated into the method for determining sprint mechanical properties [@morinSimpleMethodComputing2019; @samozinoSimpleMethodMeasuring2016]. This approach presents an advantage to practitioners who can use the outcomes to describe individual differences, quantify the effects of training interventions, and better understanding the limiting factors of performance. 

The **shorts** package [@R-shorts], written in the R language [@R-base], represents an open-source tool to help sports scientists translate raw timing data into detailed mechanical outcomes through mathematical modeling [@morinSimpleMethodComputing2019; @samozinoSimpleMethodMeasuring2016]. To best of our knowledge, scientist, researchers, and coaches have been performing short sprints modeling using the built-in solver function of Excel (Microsoft Corporation, Redmond, Washington, United States) [@morinSpreadsheetSprintAcceleration2017; @morinSpreadsheetSprintAcceleration2019; @stenrothForcevelocityProfilingIce2020; @stenrothSpreadsheetSprintAcceleration2020; @samozinoSimpleMethodMeasuring2016; @clarkNFLCombine40Yard2017; @morinSimpleMethodComputing2019], which makes the **shorts** package a major improvement in ease-of-use, speed, transparency, reproducibility, and more feature-rich model fitting. 

In the current paper, we will provide an explanation of one commonly used mathematical equation to model short sprints, modeling applications using the **shorts** package, issues that can arise during measurement and estimation, and potential solutions to those problems. 

# Mathematical model

Short sprints have been modeled using the mono-exponential equation \@ref(eq:velocity-time) originally proposed by @doi:10.1098/rspb.1927.0035, and more recently popularized by @clarkNFLCombine40Yard2017, and @samozinoSimpleMethodMeasuring2016. Equation \@ref(eq:velocity-time) represents the function for instantaneous horizontal velocity $v$ given the time $t$ and two model parameters: 

\begin{equation}
  v(t) = MSS \times (1 - e^{-\frac{t}{TAU}}) (\#eq:velocity-time)
\end{equation}

The parameters of the equation \@ref(eq:velocity-time) are *maximum sprinting speed* (MSS; expressed in $ms^{-1}$) and *relative acceleration* (TAU). Mathematically, TAU represents the ratio of MSS to initial acceleration (MAC; *maximal acceleration*, expressed in $ms^{-2}$) \@ref(eq:maximal-acceleration).

\begin{equation}
  MAC = \frac{MSS}{TAU}(\#eq:maximal-acceleration)
\end{equation}

Although TAU is used in the equations, and later estimated, we prefer to use MAC instead since it is easier to grasp, particularly for less math inclined coaches.  

By derivating equation \@ref(eq:velocity-time), we can get the equation for horizontal acceleration \@ref(eq:acceleration-time).

\begin{equation}
  a(t) = \frac{MSS}{TAU} \times e^{-\frac{t}{TAU}}  (\#eq:acceleration-time)
\end{equation}

By integrating equation \@ref(eq:velocity-time), we can get the equation for distance covered \@ref(eq:distance-time).

\begin{equation}
  d(t) = MSS \times (t + TAU \times e^{-\frac{t}{TAU}}) - MSS \times TAU  (\#eq:distance-time)
\end{equation}

Let's consider four athletes with different levels of MSS (high versus low maximal sprinting speed) and MAC (high versus low maximal acceleration; as mentioned previously, using MAC is preferred over using TAU) (Table \@ref(tab:four-athletes-table)).

```{r four-athletes-table, echo=FALSE}
athletes <- tribble(
  ~Athlete, ~MSS, ~MAC,
  "Athlete A", 12, 10,
  "Athlete B", 12, 6,
  "Athlete C", 8, 10,
  "Athlete D", 8, 6
)

athletes <- athletes %>%
  mutate(TAU = MSS / MAC)

knitr::kable(
  athletes,
  caption = "Four athletes with different MSS and MAC parameters.",
  digits = 2,
  booktabs = TRUE
)
```

Figure \@ref(fig:four-athletes-kinematics) depicts distance, velocity, and acceleration over time (from 0 to 6 s). 

```{r four-athletes-kinematics, echo=FALSE, fig.cap="Kinematic characteristic of four athletes with different MSS and MAC parameters over a period of 0 to 6 seconds."}
kinematics <- expand_grid(
  athletes,
  time = seq(0, 6, length.out = 1000)
) %>%
  mutate(
    distance = predict_distance_at_time(time, MSS, TAU),
    velocity = predict_velocity_at_time(time, MSS, TAU),
    acceleration = predict_acceleration_at_time(time, MSS, TAU)
  )

kinematics_long <- kinematics %>%
  pivot_longer(
    cols = c("distance", "velocity", "acceleration"),
    names_to = "variable"
  ) %>%
  mutate(
    variable = factor(
      variable,
      levels = c("distance", "velocity", "acceleration"),
      labels = c(
        expression("Distance (m" * ")"),
        expression("Velocity (ms"^-1 * ")"),
        expression("Acceleration (ms"^-2 * ")")
      )
    )
  )

gg <- ggplot(
  kinematics_long,
  aes(x = time, y = value, color = Athlete)
) +
  theme_bw(8) +
  geom_line(alpha = 0.7) +
  facet_wrap(
    ~variable,
    scales = "free_y",
    labeller = label_parsed
  ) +
  ylab(NULL) +
  xlab("Time (s)") +
  theme(
    legend.position = "top",
    legend.title = element_blank()
  )

plot(gg)
```

Plotting acceleration against velocity (Figure \@ref(fig:four-athletes-profile)), we will get *Acceleration-Velocity Profile*, which is linear, according to the mathematical model. If the athlete's body mass (kg) is known, as well as additional air resistance parameters (see [Air resistance and the calculation of force and mechanical power] section of this paper), *Force-Velocity Profile* can be estimated (see [Force-Velocity profile] section of this paper). 

```{r four-athletes-profile, echo=FALSE, fig.cap="Acceleration-Velocity profile of four athletes with different MSS and MAC parameters."}
gg <- ggplot(
  kinematics,
  aes(x = velocity, y = acceleration, color = Athlete)
) +
  theme_bw(8) +
  geom_line(alpha = 0.7) +
  ylab(expression("Acceleration (ms"^-2 * ")")) +
  xlab(expression("Velocity (ms"^-1 * ")")) +
  xlim(c(0, 12)) +
  theme(
    legend.position = "top",
    legend.title = element_blank()
  )

plot(gg)
```

# Estimation using shorts package

Short sprints profiling is usually performed by: (1) measuring split times using timing gates (i.e., positioned at various distances, e.g., 5, 10, 20, 30, 40 m), or (2) getting a velocity trace using a radar gun. Estimation of MSS and TAU parameters from equation \@ref(eq:velocity-time) is performed in **shorts** package using non-linear least squares regression implemented in the `nls()` function [@batesNonlinearModels1992; @batesNonlinearRegressionAnalysis2007] in the **base R** [@R-base] and `nlme()` function in the **nlme** package [@R-nlme] for the mixed-effect models.

## Estimating short sprint parameters using timing gates split times

Let's consider an example of an athlete with MSS equal to 9 $ms^{-1}$, TAU equal to 1.3, and MAC equal to 6.92 $ms^{-2}$ performing 40m sprint with timing gates positioned at each 10m split. For split times, distance is a predictor, and time is the outcome variable, thus the equation \@ref(eq:distance-time) becomes:

\begin{equation}
  t(d) = TAU \times W(-e^{\frac{-d}{MSS \times TAU}} - 1) + \frac{d}{MSS} + TAU (\#eq:time-distance)
\end{equation}

$W$ in equation \@ref(eq:time-distance) represents Lambert's W function [@R-LambertW]. Researchers often incorrectly use the equation \@ref(eq:distance-time) [@morinSpreadsheetSprintAcceleration2017; @morinSpreadsheetSprintAcceleration2019; @stenrothSpreadsheetSprintAcceleration2020], in which the time is the predictor and distance is the outcome variable, instead of statistically correct equation \@ref(eq:time-distance). This practice should be avoided because switching of the predictor and outcome variables in the regression model might produce biased estimated parameters [@motulskyIntuitiveBiostatisticsNonmathematical2018, p. 341]. This might not necessarily be the case with the short sprints profiling, but it is nevertheless a bad statistical practice.

MSS and TAU parameters are estimated using `model_using_splits()` function:

```{r}
require(shorts)

split_distance <- c(10, 20, 30, 40)

split_time <- c(2.17, 3.43, 4.60, 5.73)

m1 <- model_using_splits(
  distance = split_distance,
  time = split_time
)

m1
```

Maximal relative power (PMAX) from the output is estimated using $\frac{MSS \times MAC}{4}$, which disregards the air resistance. `time_correction` and `distance_corection` parameters will be covered later in the paper.

Besides providing *residual standard error* (RSE), **shorts** functions provide additional model fit estimators. Additional information can be gained by exploring the returned object, particularly object returned from the `nls()` function (i.e., by using the S3 `summary()` method). To extract estimated model parameters, use S3 `coef()` method. 

To create a simple plot of the model, use S3 `plot()` method, which returns **ggplot2** [@R-ggplot2] object:

```{r}
plot(m1) + theme_bw(8)
```

Once we have estimated MSS and TAU, we can use `predict_XXX()` family of functions to predict various relationships (i.e., time at distance, acceleration at distance, velocity at time, etc.):

```{r}
# Predict time at distance
predict_time_at_distance(
  distance = split_distance,
  MSS = m1$parameters$MSS,
  TAU = m1$parameters$TAU
)
```

### Air resistance and the calculation of force and mechanical power

To estimate force production at distance or time (using `predict_force_at_distance()` and `predict_force_at_time()` functions), as well as power production (using `predict_power_at_distance()` and `predict_power_at_time()` functions), one needs to take into account the air resistance. Air resistance (N) is estimated using `get_air_resistance()` function, which takes velocity, body mass (kg), body height (m), barometric pressure (Torr), air temperature ($C^\circ$), and wind velocity ($ms^-1$) as parameters (please refer to @arsacModelingEnergetics100m2002, @samozinoSimpleMethodMeasuring2016, and @vaningenschenauCanCyclePower1991 for more information):

```{r}
get_air_resistance(
  velocity = 5,
  bodymass = 80,
  bodyheight = 1.85,
  barometric_pressure = 780,
  air_temperature = 20,
  wind_velocity = 0.5
)
```

When estimating force and power, the air resistance parameters can be set using `"..."`, which are forwarded to the `get_air_resistance()`:

```{r}
# To calculate horizontal force produced
predict_force_at_distance(
  distance = split_distance,
  MSS = m1$parameters$MSS,
  TAU = m1$parameters$TAU,
  # Additional parameters forwarded to get_air_resistance
  # Otherwise, defaults are used
  bodymass = 80,
  bodyheight = 1.85,
  barometric_pressure = 780,
  air_temperature = 20,
  wind_velocity = 0.5
)
```

The easiest way to get all kinematics and kinetics for short sprints is to use `predict_kinematics()` function:

```{r}
df <- predict_kinematics(
  m1,
  max_time = 6,
  frequency = 100,
  # Additional parameters forwarded to get_air_resistance
  # Otherwise, defaults are used
  bodymass = 80,
  bodyheight = 1.85,
  barometric_pressure = 780,
  air_temperature = 20,
  wind_velocity = 0.5
)
```

Plotting the model predictions can be done once we convert data from wide to long with the help of **ggplot2** [@R-ggplot2], **dplyr** [@R-dplyr], **tidyr** [@R-tidyr], and **tidyverse** [@R-tidyverse] packages:

```{r}
require(tidyverse)

variable_names <- colnames(df)

df <- pivot_longer(data = df, cols = -2) %>%
  mutate(name = factor(name, levels = variable_names))

ggplot(df, aes(x = distance, y = value)) +
  theme_bw(8) +
  facet_wrap(~name, scales = "free_y") +
  geom_line(alpha = 0.7) +
  ylab(NULL) +
  xlab("Distance (m)")
```

These kinematic and kinetic variables are utilized in [Force-Velocity profile] estimation, which is covered later in this paper. 

### Utility functions 

Another valuable addition for sport scientists and coaches is the ability to determine the distances and times where 90% of maximum sprinting speed is reached, or where peak power is within 90% range. To identify these values, **shorts** package comes with `find_XXX()` family of functions:

```{r}
# Finds distance where 90% of maximum sprinting speed is reached
find_velocity_critical_distance(
  MSS = m1$parameters$MSS,
  TAU = m1$parameters$TAU,
  percent = 0.9
)

# Finds maximal power and distance (this time using air resistance)
find_max_power_distance(
  MSS = m1$parameters$MSS,
  TAU = m1$parameters$TAU,
  # Additional parameters forwarded to get_air_resistance
  # Otherwise, defaults are used
  bodymass = 80,
  bodyheight = 1.85,
  barometric_pressure = 780,
  air_temperature = 20,
  wind_velocity = 0.5
)

# Finds distance over 90% power range
find_power_critical_distance(
  MSS = m1$parameters$MSS,
  TAU = m1$parameters$TAU,
  # Additional parameters forwarded to get_air_resistance
  # Otherwise, defaults are used
  bodymass = 80,
  bodyheight = 1.85,
  barometric_pressure = 780,
  air_temperature = 20,
  wind_velocity = 0.5
)
```

### Mixed-effects model

Sprint performance is often evaluated with a group of athletes (e.g., soccer club) representing a single strata of interest. Sports scientists can estimate individual profiles, or utilize mixed-effects models. To perform mixed-effects models in **shorts** for split times, one can use `mixed_model_using_splits()` function. To demonstrate this functionality, we load the `split_times` dataset provided in the **shorts** package:

```{r}
data(split_times)

# Mixed model
m2 <- mixed_model_using_splits(
  data = split_times,
  distance = "distance",
  time = "time",
  athlete = "athlete",

  # Select random effects
  # Default is MSS and TAU
  random = MSS + TAU ~ 1
)

m2
```

Additional information about mixed-effects model performed using the `nlme` package [@R-nlme] can be obtained using `summary()` function. S3 method `coef()` when applied on mixed-model result will return both the fixed and random effects. 

```{r include=FALSE}
summary(m2)
coef(m2)
```

To create a simple plot of the model, use S3 `plot()` method. 

```{r}
plot(m2) + theme_bw(8)
```

The following figure contains kinematics for all athletes in `split_times` dataset. Please note that power calculation takes default parameters for each individual:

```{r}
df <- predict_kinematics(m2, max_time = 10)

variable_names <- colnames(df)

df <- pivot_longer(df, cols = c(-1, -3)) %>%
  mutate(name = factor(name, levels = variable_names))

ggplot(
  filter(df, distance < 40),
  aes(x = distance, y = value, group = athlete, color = athlete)
) +
  theme_bw(8) +
  facet_wrap(~name, scales = "free_y") +
  geom_line(alpha = 0.7) +
  ylab(NULL) +
  xlab("Distance (m)") +
  theme(
    legend.position = "top",
    legend.title = element_blank()
  )
```

## Estimating short sprint parameters using radar gun

Estimation of the short sprint profile using radar gun data takes time as predictor and velocity as the outcome variable. Thus equation \@ref(eq:velocity-time) is used to estimate MSS and TAU. 

Let's consider the same example of an athlete with MSS equal to 9 $ms^{-1}$, TAU equal to 1.3, and MAC equal to 6.92 $ms^{-2}$ performing 40m sprint with velocity estimated using radar run (in this case with 1 Hz sampling rate).

```{r}
sprint_time <- seq(0, 6, 1)

sprint_velocity <- c(0.00, 4.83, 7.07, 8.10, 8.59, 8.81, 8.91)

m3 <- model_using_radar(
  velocity = sprint_velocity,
  time = sprint_time
)
```

Both split and radar gun models allow the use of *weighted* non-linear regression. Weighting in regression is utilized when the observations have unequal error variance [@gelmanRegressionOtherStories2020], which can happen due to instrumental error (e.g., a multiplicative error instead of additive error) or due to biological variability (e.g., higher split time variance on shorter distances versus longer distances). In this case, observations with higher error variance get lower weight when fitting the model [@gelmanRegressionOtherStories2020]. According to @gelmanRegressionOtherStories2020, unequal variances are not typically a major issue for the goal of estimating regression parameters, but they can become more important when making predictions about individual observations. Further exploring the topic of unequal error variances is beyond the scope of this paper, but the **shorts** package provides a weighting feature for the potential research of this topic in the future. 

Weighted non-linear regression is performed by setting `weights` parameter. For example, we can give more weight to shorter distances or faster velocities:

```{r}
m3_weighted <- model_using_radar(
  velocity = sprint_velocity,
  time = sprint_time,
  weights = 1 / (sprint_velocity + 1)
)
```


### Mixed-effects model

Mixed-effects model using radar data is done using `mixed_model_using_radar()` function. To perform mixed model, let's load data that comes with **shorts** package. 

```{r}
data("radar_gun_data")

m4 <- mixed_model_using_radar(
  radar_gun_data,
  time = "time",
  velocity = "velocity",
  athlete = "athlete"
)
```

## Force-Velocity profile

To create *Force-Velocity Profile* (FVP) using single athlete estimated sprint model parameters (i.e., TAU and MSS), you can use `get_FV_profile()` function. When estimating FVP, athlete body mass (kg) can be set using `bodymass` parameter, while the air resistance parameters can be set using `"..."`, which are forwarded to the `get_air_resistance()` function. Details of the FVP method implemented in the **shorts** package, as well as the interpretation from a sprint training perspective, are covered elsewhere [@haugenPowerForceVelocityProfilingSprinting2020; @morinInterpretingPowerForceVelocityProfiles2016; @morinSimpleMethodComputing2019; @samozinoSimpleMethodMeasuring2016]. 

```{r}
# To create Force-Velocity Profile
fvp <- get_FV_profile(
  MSS = m1$parameters$MSS,
  TAU = m1$parameters$TAU,
  bodymass = 80,
  # Additional parameters forwarded to get_air_resistance
  # Otherwise, defaults are used
  bodyheight = 1.85,
  barometric_pressure = 780,
  air_temperature = 20,
  wind_velocity = 0.5
)

fvp
```

To plot FVP kinematics and kinetics (which are exactly the same as generated by the `predict_kinematics()` function), use S3 `plot()` function. By default, FVP estimated kinetics are plotted against velocity (on x-axis). 

```{r}
plot(fvp) + theme_bw(8)
```

To plot FVP estimated kinetics against time, use `type = "time"` parameter:

```{r results='hide', fig.show='hide'}
plot(fvp, "time") + theme_bw(8)
```

# Problems with estimation

There is a challenge when collecting sprint data that could have a substantial impact on modeled outcomes. To ensure accurate parameter outcomes, the initial force production must be synced with start time [@haugenPowerForceVelocityProfilingSprinting2020; @haugenSprintMechanicalVariables2019]. Below we describe this challenge when using radar guns or timing gates and suggest potential solutions within the **shorts** package.

## Problems with time sync with radar gun

One source of error in the modeled estimation using a radar gun is the time synchronization. In theory, synchronization is ideal when a sprint is initiated at $t=0$ (i.e., $v(t=0) = 0$). In practice, this is often not the case. Let's use our athlete and add and deduct 0.5 s to simulate an error in synchronization and its effect on estimated MSS and TAU.

```{r}
df <- tibble(
  `true time` = sprint_time,
  velocity = sprint_velocity,
  `0.5s added` = `true time` + 0.5,
  `0.5s deducted` = `true time` - 0.5
)

plot_df <- pivot_longer(df, cols = -2, names_to = "Sync issue")

ggplot(
  plot_df,
  aes(x = value, y = velocity, color = `Sync issue`)
) +
  theme_bw(8) +
  geom_line(alpha = 0.7) +
  xlab("Time (s)") +
  ylab(expression("Velocity (" * ms^-1 * ")")) +
  theme(
    legend.title = element_blank(),
    legend.position = "top"
  )
```

The following three models estimate MSS and TAU from the three datasets. Tables are created using the `kable()` function from the **knitr** package [@knitr2014; @knitr2015; @R-knitr] and `kable_styling()` function from the **kableExtra** package [@R-kableExtra]. 

```{r}
require(knitr)

# Without synchronization issues
m5 <- model_using_radar(
  velocity = df$velocity,
  time = df$`true time`
)

# With time added
m6 <- model_using_radar(
  velocity = df$velocity,
  time = df$`0.5s added`
)

# With time deducted
m7 <- model_using_radar(
  velocity = df$velocity,
  time = df$`0.5s deducted`
)

model_df <- rbind(
  data.frame(
    model = "True time",
    t(coef(m5))
  ),
  data.frame(
    model = "Added 0.5s time",
    t(coef(m6))
  ),
  data.frame(
    model = "Deducted 0.5s time",
    t(coef(m7))
  )
)

kable(model_df, digits = 2, booktabs = TRUE)
```

As can be seen from the example, all estimated parameters are affected by an error in synchronization of time with velocity (with MSS being the least affected in this example). The potential solution incorporated into the **shorts** package involves estimation of the *time correction* parameter using the following equation: 

\begin{equation}
  v(t) = MSS \times (1 - e^{-\frac{t + time \; correction}{TAU}}) (\#eq:velocity-time-correction)
\end{equation}

This model is incorporated in the `model_using_radar_with_time_correction()` function:

```{r}
# With time added
m8 <- model_using_radar_with_time_correction(
  velocity = df$velocity,
  time = df$`0.5s added`
)
coef(m8)

# With time deducted
m9 <- model_using_radar_with_time_correction(
  velocity = df$velocity,
  time = df$`0.5s deducted`
)
coef(m9)
```

When using `predict_XXX()` family of functions, one can provide estimated time correction to get predictions at original time scale. 

```{r}
# Using the true time
predict_velocity_at_time(
  time = df$`true time`,
  MSS = m5$parameters$MSS,
  TAU = m5$parameters$TAU
)

# Using time with sync issues
predict_velocity_at_time(
  time = df$`0.5s added`,
  MSS = m8$parameters$MSS,
  TAU = m8$parameters$TAU,
  time_correction = m8$parameters$time_correction
)
```

### Mixed-model approach

When it comes to mixed-model approach, time correction can be modeled as a fixed effect or random effect using the `mixed_model_using_radar_with_time_correction()` function. 

```{r}
# Adding 0.5s to radar_gun_data
radar_gun_data$time <- radar_gun_data$time + 0.5

# Mixed model with time correction being fixed effect
m10 <- mixed_model_using_radar_with_time_correction(
  radar_gun_data,
  time = "time",
  velocity = "velocity",
  athlete = "athlete",
  random = MSS + TAU ~ 1
)

# Mixed model with time correction being random effect
m11 <- mixed_model_using_radar_with_time_correction(
  radar_gun_data,
  time = "time",
  velocity = "velocity",
  athlete = "athlete",
  random = MSS + TAU + time_correction ~ 1
)
```

## Problems at the start when using timing gates

Let's imagine we have two twin brothers with same short sprint characteristics: MSS equal to 9 $ms^{-1}$, TAU equal to 1.3, and MAC equal to 6.92 $ms^{-2}$. Let's call them John and Jack. They both perform 40m sprint using timing gates set at 5, 10, 20, 30, and 40 m. The initial timing gate at the start (i.e., $d=0$ m) serves to activate the timing system (i.e., when they cross the beam).

John represents the *theoretical model*, in which we assume that the initial force production and the timing initiation are perfectly synchronized. Jack, on the other hand, represents a *practical model*, and decides to move slightly behind the initial timing gate (i.e. for 0.5 m) and use body rocking to initiate the sprint start. In other words, Jack is using a *flying start*, a common scenario when testing field sports athletes. Flying start distance is often recommended to avoid premature triggering of the timing system by lifted knees or swinging
arms [@altmannAccuracySingleBeam2018; @altmannDifferentStartingDistances2015; @altmannValiditySingleBeamTiming2017; @haugenPowerForceVelocityProfilingSprinting2020; @haugenSprintRunningPerformance2016].

```{r}
MSS <- 9
TAU <- 1.3
MAC <- MSS / TAU

split_times <- tibble(
  distance = c(5, 10, 20, 30, 40),
  john_time = predict_time_at_distance(distance, MSS, TAU),

  # Jack's performance
  jack_distance = distance + 0.5,
  jack_true_time = predict_time_at_distance(jack_distance, MSS, TAU),
  time_05m = predict_time_at_distance(0.5, MSS, TAU),
  jack_time = jack_true_time - time_05m
)
```

Here is a graphical representation of the sprint splits (please refer to the [Supplemental material] for the R code):

```{r echo=FALSE}
plot_df <- split_times %>%
  select(distance, john_time, jack_time) %>%
  rename(John = john_time, Jack = jack_time) %>%
  pivot_longer(cols = -1, names_to = "athlete", values_to = "time") %>%
  mutate(distance = factor(distance))

ggplot(
  plot_df,
  aes(x = distance, y = time, color = athlete, group = athlete)
) +
  theme_bw(8) +
  geom_point() +
  geom_line() +
  xlab("Distance (m)") +
  ylab("Time (s)") +
  theme(
    legend.title = element_blank(),
    legend.position = "top"
  )
```

Using the following code, we can see the differences in estimated MSS and TAU parameters:

```{r}
# Since this is a perfect simulation and stats::nls will complain
# we need to add very small noise, or measurement error to the times
set.seed(1667)
rand_noise <- rnorm(nrow(split_times), 0, 10^-5)
split_times$john_time <- split_times$john_time + rand_noise
split_times$jack_time <- split_times$jack_time + rand_noise

john_profile <- model_using_splits(
  distance = split_times$distance,
  time = split_times$john_time
)

jack_profile <- model_using_splits(
  distance = split_times$distance,
  time = split_times$jack_time
)

sprint_parameters <- rbind(
  coef(john_profile),
  coef(jack_profile)
)

rownames(sprint_parameters) <- c("John", "Jack")

kable(sprint_parameters, digits = 2, booktabs = TRUE)
```

As can be seen from the results, a flying start yields biased estimates, particularly for the TAU, MAC and PMAX.

To explore this further, we have run a simple simulation by increasing Jack's flying start distance from 0 to 1 m and depicting the estimated MSS, TAU, MAC, and PMAX parameters (please refer to the [Supplemental material] for the R code).

```{r include=FALSE}
sim_df <- expand.grid(
  MSS = 9,
  MAC = 9 / 1.3,
  flying_start_distance = seq(0.0001, 1, length.out = 1000),
  distance = c(5, 10, 20, 30, 40)
)

sim_df <- sim_df %>%
  mutate(
    TAU = MSS / MAC,
    PMAX = MSS * MAC / 4,
    true_distance = distance + flying_start_distance,
    true_time = predict_time_at_distance(true_distance, MSS, TAU),
    stolen_time = predict_time_at_distance(
      flying_start_distance, MSS, TAU
    ),
    time = true_time - stolen_time
  )

# Add small noise to allow model fit
set.seed(1667)
rand_noise <- rnorm(nrow(sim_df), 0, 10^-5)
sim_df$time <- sim_df$time + rand_noise
```

```{r include=FALSE}
# Prediction wrapper
pred_wrapper <- function(data) {
  model <- model_using_splits(
    distance = data$distance,
    time = data$time
  )

  params <- data.frame(t(coef(model)))

  predicted_time <- predict_time_at_distance(
    distance = data$distance,
    MSS = model$parameters$MSS,
    TAU = model$parameters$TAU
  )

  colnames(params) <- c(
    "est_MSS", "est_TAU", "est_MAC", "est_PMAX",
    "est_time_correction", "est_distance_correction"
  )

  cbind(
    data,
    params,
    data.frame(predicted_time = as.numeric(predicted_time))
  )
}

# estimated parameters and predicted time
model_df <- sim_df %>%
  group_by(MSS, TAU, flying_start_distance) %>%
  do(pred_wrapper(.)) %>%
  ungroup()

# Prediction residuals
model_df$residuals <-  model_df$time - model_df$predicted_time
```

```{r echo=FALSE}
# Estimates plot
plot_df <- model_df %>%
  group_by(MSS, TAU, flying_start_distance) %>%
  slice(1) %>%
  mutate(
    `MSS (m/s)` = est_MSS,
    `TAU` = est_TAU,
    `MAC (m/s/s)` = est_MAC,
    `PMAX (W)` = est_PMAX
  ) %>%
  pivot_longer(cols = c("MSS (m/s)", "TAU", "MAC (m/s/s)", "PMAX (W)")) %>%
  mutate(
    name = factor(name, levels = c("MSS (m/s)", "TAU", "MAC (m/s/s)", "PMAX (W)"))
  )

ggplot(plot_df, aes(x = flying_start_distance, y = value)) +
  theme_bw(8) +
  geom_line(alpha = 0.7) +
  facet_wrap(~name, scales = "free_y") + 
  xlab("Flying start distance (m)") +
  ylab("Estimated parameter")
```

As can be seen from the figure, MSS is underestimated as flying start distance increases. MAC (and also TAU) are highly affected by the flying start distance, and from the figure we can notice that MAC is overestimated as flying start distance increases. Estimated PMAX is also overestimated as flying start distance increases.

Model residuals are also affected by the flying start distance. The shape of residuals distribution depends on number and splits utilized (e.g., 10, 20, 30, 40 m versus 5, 15, 30 m), but here we can see the effect of the flying start distance on the model residuals per split distance utilized in our simple simulation:

```{r echo=FALSE}
# Residuals
plot_df <- model_df %>%
  mutate(
    distance_string = paste0(distance, "m"),
    distance_string = factor(
      distance_string,
      levels = c("5m", "10m", "20m", "30m", "40m")
    )
  )

ggplot(
  plot_df,
  aes(
    y = residuals,
    x = flying_start_distance,
  )
) +
  theme_bw(8) +
  geom_line() +
  facet_wrap(~distance_string) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  xlab("Flying start distance (m)") +
  ylab("Observed time - predicted time (s)")
```

Another way to visualize the effect of the flying start distance on split distance residuals can be found on the next figure:

```{r echo=FALSE}
# Residuals
ggplot(
  model_df,
  aes(
    y = residuals,
    x = distance,
    color = flying_start_distance,
    group = flying_start_distance
  )
) +
  theme_bw(8) +
  geom_line(alpha = 0.3) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_color_gradientn(colours = terrain.colors(5, rev = FALSE)) +
  xlab("Distance (m)") +
  ylab("Observed - predicted time (s)") +
  theme(legend.position = "top") +
  labs(color = "Flying start distance")
```

Clearly, any type of flying start where there is a difference between initial force production and start time can result in biased parameters and predictions. Since maximal sprint speed is difficult to improve, the effects of start inconsistencies can mask effects of the training intervention. It is thus crucial to standardize the start when testing and implementing the following techniques when using the **shorts** package. 

### How to overcome missing the initial force production when using timing gates?

A potential solution is to use a correction factor - the recommendation in the literature is +0.5 s [@haugenSprintMechanicalProperties2020; @haugenSprintMechanicalVariables2019]. Interestingly, the average difference between using timing gates and a block start for 40 m sprint time was 0.27 s [@haugenDifferenceStartImpact2012]. So, while a timing correction factor is warranted to avoid subsequent errors in estimates of kinetic variables (e.g., overestimate power), a correction factor that is too large will have the opposite effect (e.g., underestimate power).  

Rather than providing *apriori* time correction from the literature, **shorts** package provides an estimation of this parameter from the data provided, together with MSS and TAU. Exactly the same method is suggested by @stenrothForcevelocityProfilingIce2020, named *time shift method*, and the estimated parameter named *time shift parameter*. We have named this parameter *time correction* to be in agreement with the parameter introduced in [Problems with time sync with radar gun] section of this paper, as well as the available literature. 

When implementing time correction, equation \@ref(eq:time-distance) becomes:

\begin{equation}
  t(d) = TAU \times W(-e^{\frac{-d}{MSS \times TAU}} - 1) + \frac{d}{MSS} + TAU - time \; correction (\#eq:time-correction)
\end{equation}

To estimate time correction parameter, we use `model_using_splits_with_time_correction()` function. Here is how we can estimate Jack parameters using either provided time correction (e.g., +0.3 and +0.5 s) or estimated time correction:

```{r}
jack_profile_fixed_time_short <- model_using_splits(
  distance = split_times$distance,
  time = split_times$jack_time,
  time_correction = 0.3
)

jack_profile_fixed_time_long <- model_using_splits(
  distance = split_times$distance,
  time = split_times$jack_time,
  time_correction = 0.5
)

jack_profile_time_estimated <- model_using_splits_with_time_correction(
  distance = split_times$distance,
  time = split_times$jack_time
)

jack_parameters <- rbind(
  coef(john_profile),
  coef(jack_profile),
  coef(jack_profile_fixed_time_short),
  coef(jack_profile_fixed_time_long),
  coef(jack_profile_time_estimated)
)

rownames(jack_parameters) <- c(
  "John",
  "Jack - No corrections",
  "Jack - Fixed time correction (+0.3s)",
  "Jack - Fixed time correction (+0.5s)",
  "Jack - Estimated time correction"
)

kable(jack_parameters, digits = 2, booktabs = TRUE)
```

In Jack's case, both +0.3 s fixed time correction and time correction estimation yield parameters closer to John's (i.e. true parameters). We have used these two model definitions in retrospective pilot study [@vescoviSprintMechanicalCharacteristics2021], demonstrating statistically significant differences in estimated FVP parameters.

Instead of using time correction as simple intercept in the equation \@ref(eq:time-correction), we can estimate the *distance correction* (i.e., the flying start distance) using the following equation:

\begin{equation}
  \begin{split}
   t(d) &= (TAU \times W(-e^{\frac{-d + distance \; correction}{MSS \times TAU}} - 1) + \frac{d + distance \; correction}{MSS} + TAU) \\ 
   &\quad-(TAU \times W(-e^{\frac{distance \; correction}{MSS \times TAU}} - 1) + \frac{distance \; correction}{MSS} + TAU) 
   \end{split}
   (\#eq:distance-correction)
\end{equation}

Equation \@ref(eq:distance-correction) was used to generate the data for John and Jack (please refer to the provided R code), as well as for the simple simulation, and can be used as model definition to control for the flying start distance. 

To estimate distance correction parameter, we use `model_using_splits_with_distance_correction()` function. Here is how we can estimate Jack parameters using distance correction:

```{r}
jack_profile_distance_correction <- model_using_splits_with_distance_correction(
  distance = split_times$distance,
  time = split_times$jack_time
)

jack_parameters <- rbind(
  jack_parameters,
  coef(jack_profile_distance_correction)
)

rownames(jack_parameters) [6] <- "Jack - Estimated distance correction"

kable(jack_parameters, digits = 2, booktabs = TRUE) 
```

Another model definition, which also represents a novel approach implemented in the **shorts** package, is to utilize both time and distance corrections. Thus, equation \@ref(eq:time-correction) becomes:

\begin{equation}
  t(d) = TAU \times W(-e^{\frac{-d + distance \; correction}{MSS \times TAU}} - 1) + \frac{d + distance \; correction}{MSS} + TAU - time \; correction (\#eq:time-distance-correction)
\end{equation}

This model is implemented in `model_using_splits_with_corrections()` function. Below are the model estimates:

```{r}
jack_profile_time_distance_correction <- model_using_splits_with_corrections(
  distance = split_times$distance,
  time = split_times$jack_time
)

jack_parameters <- rbind(
  jack_parameters,
  coef(jack_profile_time_distance_correction)
)

rownames(jack_parameters) [7] <- 
  "Jack - Estimated time & distance corrections"

kable(jack_parameters, digits = 2, booktabs = TRUE)
```

As can be seen from the results, adding distance correction results in correctly estimating Jack's sprint parameters. There are a few issues with this model definition. Besides being novel and still not validated with actual data, distance correction model has four parameters to estimate, which implies that at least four sprint splits are needed. This imposes practical limitations, since acquiring five timing gates (one for the start and four for splits) might be practically troublesome. One strategy that is sometimes implemented is adding zeros to the sample (i.e., $t=0$ and $d=0$), which increase the number of observations. Unfortunately, this strategy should not be implemented since it will bias the estimated parameters:

```{r}
jack_profile_zero <- model_using_splits(
  distance = c(0, split_times$distance),
  time = c(0, split_times$jack_time)
)

jack_profile_time_estimated_zero <- model_using_splits_with_time_correction(
  distance = c(0, split_times$distance),
  time = c(0, split_times$jack_time)
)

adding_zero_issue <- rbind(
  coef(jack_profile),
  coef(jack_profile_zero),
  coef(jack_profile_time_estimated),
  coef(jack_profile_time_estimated_zero)
)

rownames(adding_zero_issue) <- c(
  "Jack - No corrections",
  "Jack - No corrections with zeros added",
  "Jack - Estimated time correction",
  "Jack profile - Estimated time correction with added zeros")

kable(adding_zero_issue, digits = 2, booktabs = TRUE)
```

Adding zeros to the sample nullifies the potential benefits of using time correction model and should be avoided in practice.

It is important to note that using `predict_XXX()` family of functions with distance correction model and using estimated distance correction parameter will yield wrong predictions on the original scale (but not on the *theoretical* scale in which force production starts at d=0m and t=0s). This is because `predict_XXX()` family of functions utilize equation \@ref(eq:time-distance-correction) and its derivates and integrals, which works for the uncorrected model (time and distance correction parameters are equal to zero), time correction models (distance correction parameter is equal to zero), and time and distance corrections model. You can notice that equations \@ref(eq:time-correction) and \@ref(eq:time-distance-correction) are equivalent to the \@ref(eq:time-distance) equation when time and distance correction parameters are equal to zero. Unfortunately, this doesn't work for the distance correction model when the estimated distance correction parameter is used since model definition outlined in the equation \@ref(eq:distance-correction) is different that the equation \@ref(eq:time-distance-correction) when the estimated distance correction parameter is different than zero. The solution is to use generic S3 `predict()` function, but this only predicts split times at split distances. 

```{r}
# Jack's observed times
split_times$jack_time

# To predict at "theoretical" distance scale (where force application starts at d=0m)
predict_time_at_distance(
  distance = split_times$distance, 
  MSS = jack_profile_time_estimated$parameters$MSS,
  TAU = jack_profile_time_estimated$parameters$TAU)

predict_time_at_distance(
  distance = split_times$distance, 
  MSS = jack_profile_distance_correction$parameters$MSS,
  TAU = jack_profile_distance_correction$parameters$TAU)

# To predict at original distance scale, use all estimated parameters
predict_time_at_distance(
  distance = split_times$distance, 
  MSS = jack_profile_time_estimated$parameters$MSS,
  TAU = jack_profile_time_estimated$parameters$TAU,
  time_correction = jack_profile_time_estimated$parameters$time_correction)

# Unfortunately, this doesn't work for the distance correction model
predict_time_at_distance(
  distance = split_times$distance, 
  MSS = jack_profile_distance_correction$parameters$MSS,
  TAU = jack_profile_distance_correction$parameters$TAU,
  distance_correction = jack_profile_distance_correction$parameters$distance_correction)

# Instead use generic S3 predict() function
predict(jack_profile_distance_correction)

predict(
  jack_profile_distance_correction$model,
  newdata = data.frame(distance = split_times$distance))
```

In the next section we examine how these models (no correction, fixed time correction, estimated time correction, estimated distance correction, and estimated time and distance correction) perform using simulated data with varying flying start distance (please refer to the [Supplemental material] for the R code).

```{r echo=FALSE}
pred_wrapper <- function(data) {
  
  merge_model <- function(data, model, model_name) {
    data$model <- model_name
    data$est_MSS <- model$parameters$MSS
    data$est_TAU <- model$parameters$TAU
    data$est_MAC <- model$parameters$MAC
    data$est_PMAX <- model$parameters$PMAX
    data$est_time_correction <- model$parameters$time_correction
    data$est_distance_correction <- model$parameters$distance_correction
    data$predicted_time <- model$data$pred_time
    data$residuals <- data$time - data$predicted_time
      
    data
  }
  
  no_correction <- model_using_splits(
    distance = data$distance,
    time = data$time
  )
  
  fixed_correction_short <- model_using_splits(
    distance = data$distance,
    time = data$time,
    time_correction = 0.3
  )

  fixed_correction_long <- model_using_splits(
    distance = data$distance,
    time = data$time,
    time_correction = 0.5
  )

  time_correction <- model_using_splits_with_time_correction(
    distance = data$distance,
    time = data$time,
    control = nls.control(warnOnly = TRUE)
  )

  distance_correction <- model_using_splits_with_distance_correction(
    distance = data$distance,
    time = data$time,
    control = nls.control(warnOnly = TRUE)
  )
  
  time_dist_correction <- model_using_splits_with_corrections(
    distance = data$distance,
    time = data$time,
    control = nls.control(warnOnly = TRUE)
  )

  rbind(
    merge_model(
      data, 
      no_correction,
      "No correction"
    ),
    merge_model(
      data, 
      fixed_correction_short,
      "Fixed correction +0.3s"
    ),
    merge_model(
      data, 
      fixed_correction_long,
      "Fixed correction +0.5s"
    ),
    merge_model(
      data, 
      time_correction,
      "Time correction"
    ),
    merge_model(
      data, 
      distance_correction,
      "Distance correction"
    ),
    merge_model(
      data, 
      time_dist_correction,
      "Time and distance correction"
    )
  )
}

# estimated parameters and predicted time
model_df <- sim_df %>%
  filter(flying_start_distance > 0) %>%
  group_by(MSS, TAU, flying_start_distance) %>%
  do(pred_wrapper(.)) %>%
  ungroup()
```

As can be seen from the next figure, the estimated time correction model estimates MSS almost perfectly, while the estimated distance and estimate time and distance correction models estimates MSS perfectly. 

```{r echo=FALSE}
model_df$model <- factor(
  model_df$model,
  levels = c(
    "No correction",
    "Fixed correction +0.3s",
    "Fixed correction +0.5s",
    "Time correction",
    "Distance correction",
    "Time and distance correction"
  )
)

# Estimates plot
plot_df <- model_df %>%
  group_by(model, MSS, TAU, flying_start_distance) %>%
  slice(1) %>%
  mutate(
    `MSS (m/s)` = est_MSS,
    `TAU` = est_TAU,
    `MAC (m/s/s)` = est_MAC,
    `PMAX (W)` = est_PMAX
  ) %>%
  pivot_longer(cols = c("MSS (m/s)", "TAU", "MAC (m/s/s)", "PMAX (W)")) %>%
  mutate(
    name = factor(name, levels = c("MSS (m/s)", "TAU", "MAC (m/s/s)", "PMAX (W)"))
  )

ggplot(plot_df, aes(x = flying_start_distance, y = value, group = model, color = model)) +
  theme_bw(8) +
  geom_line(alpha = 0.7) +
  facet_wrap(~name, scales = "free_y") + 
  xlab("Flying start distance (m)") +
  ylab("Estimated parameter") +
  theme(
    legend.title = element_blank(),
    legend.position = "top"
  )
```

Similar outcomes are observed for the MAC parameter. The distance correction model and time and distance corrections models performs perfectly, while the time correction model performs almost as good. PMAX demonstrates the same properties as MSS and MAC. 

The next figure depicts residuals across split distances for each simulated flying start distance. As can be seen, time correction, distance correction, and time and distance correction models perform much better than the other models.

```{r}
# Residuals
ggplot(
  model_df,
  aes(
    y = residuals,
    x = distance,
    color = flying_start_distance,
    group = flying_start_distance
  )
) +
  theme_bw(8) +
  geom_line(alpha = 0.3) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_color_gradientn(colours = terrain.colors(5, rev = FALSE)) +
  facet_wrap(~model) +
  xlab("Distance (m)") +
  ylab("Observed - predicted time (s)") +
  theme(legend.position = "top") +
  labs(color = "Flying start distance")
```

The outcomes from this simple simulation data clearly demonstrates that the time correction, distance correction, and time and distance correction models represent sound improvements in parameter estimation and model fit compared to no corrections model and fixed correction model when attempting to overcome the flying start issues. Since the time correction and distance correction models are simpler and requires three parameters to be estimated, they might be practically more useful than the time and distance correction model, which requires four parameters estimation and thus more than four timing gates and sprint splits. More elaborate simulation study is currently ongoing and the results will be reported in another paper.

Time correction, distance correction, and time and distance corrections are also implemented in the mixed-models using `mixed_model_using_splits_with_time_correction()`, `mixed_model_using_splits_with_distance_correction()`, and `mixed_model_using_splits_with_corrections()` functions. We will showcase their use at the end of this paper.

# Leave-one-out Cross-Validation

To estimate parameter stability, model over-fitting, and performance on unseen data, **shorts** model function comes with implemented *leave-one-out cross validation* (LOOCV) [@jamesIntroductionStatisticalLearning2017; @jovanovicBmbstatsBootstrapMagnitudebased2020; @kuhnAppliedPredictiveModeling2018]. LOOCV involves a simple, yet powerful procedure, of removing each observation, rebuilding the model, and making predictions for that removed observation. This process is repeated for each observation in the model dataset. LOOCV allows one to check estimated parameters stability, and model performance on unseen data. 

Let's perform LOOCV using Jack's data and the time correction model:

```{r}
jack_LOOCV <- model_using_splits_with_time_correction(
  distance = split_times$distance,
  time = split_times$jack_time,
  LOOCV = TRUE
)
```

The model print output provides training dataset estimates and model performance, as well as LOOCV estimates and model performance. 

Next we plot estimated parameters across LOOCV folds (please refer to the [Supplemental material] for the R code):

```{r echo=FALSE}
df <- jack_LOOCV$LOOCV$parameters

df <- pivot_longer(df, cols = 1:6, names_to = "parameter")

df$parameter <- factor(
  df$parameter,
  levels = c(
    "MSS",
    "TAU",
    "MAC",
    "PMAX",
    "time_correction",
    "distance_correction"
  )
)

ggplot(df, aes(x = value)) +
  theme_bw(8) +
  geom_boxplot() +
  facet_wrap(~parameter, scales = "free_x") +
  xlab(NULL) +
  ylab(NULL) +
  theme(
    axis.ticks.y = element_blank(),
    axis.text.y = element_blank()
  )
```

Here is the plot of the training and LOOCV residuals:

```{r echo=FALSE}
df <- data.frame(
  distance = jack_LOOCV$data$distance,
  time = jack_LOOCV$data$time,
  pred_time = jack_LOOCV$data$pred_time,
  LOOCV_time = jack_LOOCV$LOOCV$data$pred_time
)

df <- df %>%
  pivot_longer(cols = c("pred_time", "LOOCV_time"))

df$resid <- df$value - df$time

ggplot(df, aes(x = distance, y = resid, color = name)) +
  theme_bw(8) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  theme(legend.title = element_blank()) +
  xlab("Distance (m)") +
  ylab("Observed - predicted time (s)") +
  theme(
    legend.title = element_blank(),
    legend.position = "top"
  )
```

As expected, the model has more issues predicting unseen split times for both short or long distances. Please note, that since LOOCV removes one observation, if the model estimates three parameters, then at least four observations are needed, since we need to make sure the model can be estimated once a single observation is removed. LOOCV can also be implemented with the mixed-effects models in the **shorts** package. 

# Example analysis

Let's utilize demonstrated functionalities of the **shorts** package using real-world data. The first dataset comes from Usain Bolt's performance from IAAF World Championship held in London, 2017, and the second dataset involve Jason Vescovi's sample data for 52 female soccer and field hockey athletes which comes with the **shorts** package (see the dataset documentation by executing `?vescovi` command in the R console). 

## Usain Bolt's run from London 2017

The following dataset represents Usain Bolt's race in the finals at the IAAF World Championship held in London, 2017. Since reaction time enters the splits, we want to see how that will affect the model estimates, and particularly, if the estimated time correction model will pick-up reaction time. 

For the sake of this analysis, only 10 m splits over 60 m race distance are used. 

```{r}
bolt_reaction_time <- 0.183

bolt_distance <- c(10, 20, 30, 40, 50, 60)
bolt_time <- c(1.963, 2.983, 3.883, 4.763, 5.643, 6.493)

# No corrections model
bolt_m1 <- model_using_splits(
  distance = bolt_distance,
  time = bolt_time
)

# Model with reaction time as fixed time correction
bolt_m2 <- model_using_splits(
  distance = bolt_distance,
  time = bolt_time,
  time_correction = -bolt_reaction_time
)

# Model with estimated time correction
bolt_m3 <- model_using_splits_with_time_correction(
  distance = bolt_distance,
  time = bolt_time
)

# Model with estimated time correction, but deducted reaction time
bolt_m4 <- model_using_splits_with_time_correction(
  distance = bolt_distance,
  time = bolt_time - bolt_reaction_time
)

# Model with estimated time and distance corrections
bolt_m5 <- model_using_splits_with_corrections(
  distance = bolt_distance,
  time = bolt_time
)

# Model with estimated time and distance corrections and
#  deducted reaction time
bolt_m6 <- model_using_splits_with_corrections(
  distance = bolt_distance,
  time = bolt_time - bolt_reaction_time
)

bolt_model <- rbind(
  data.frame(
    model = "No correction",
    t(coef(bolt_m1))
  ),
  data.frame(
    model = "No correction - RT",
    t(coef(bolt_m2))
  ),
  data.frame(
    model = "Time correction",
    t(coef(bolt_m3))
  ),
  data.frame(
    model = "Time correction - RT",
    t(coef(bolt_m4))
  ),
  data.frame(
    model = "Distance correction",
    t(coef(bolt_m5))
  ),
  data.frame(
    model = "Distance correction - RT",
    t(coef(bolt_m6))
  )
)

kable(bolt_model, digits = 2, booktabs = TRUE)
```

Here is the model estimate of the time and distance it takes for Bolt to reach 99% of MSS. Please note that we are not using distance and time correction parameters, since we want these estimates to be on the time/distance scale aligned with the actual sprint start (i.e., theoretical scale), not the measurement scale.

```{r}
bolt_model <- bolt_model %>%
  group_by(model) %>%
  mutate(
    dist_99_MSS = find_velocity_critical_distance(
      MSS = MSS, TAU = TAU,
      # time_correction = time_correction,
      # distance_correction = distance_correction,
      percent = 0.99
    ),
    time_99_MSS = find_velocity_critical_time(
      MSS = MSS, TAU = TAU,
      # time_correction = time_correction,
      percent = 0.99
    )
  )

kable(bolt_model[c(1, 8, 9)], digits = 2, booktabs = TRUE)
```

## Vescovi data

The data from Vescovi represents a sub-set of data from a total of 220 high-level female athletes (151 soccer players and 69 field hockey players) [@vescoviSprintMechanicalCharacteristics2021]. Using a random number generator, a total of 52 players (35 soccer and 17 field hockey) were selected for the sample dataset.

The protocol for assessing linear sprint speed has been described previously [@vescoviImpactMaximumSpeed2014; @vescoviLocomotorHeartRateMetabolic2016; @vescoviSprintSpeedCharacteristics2012] and was identical for each cohort.  Briefly, all athletes performed a standardized warm-up that included general exercises such as jogging, shuffling, multi-directional movements, and dynamic stretching exercises. Infrared timing gates (Brower Timing, Utah) were positioned at the start line and at 5, 10, 20, 30, and 35 m at a height of approximately 1.0 m. Participants stood with their lead foot positioned approximately 5 cm behind the initial infrared beam (i.e., start line). Only forward movement was permitted (no leaning or rocking backwards) and timing started when the laser of the starting gate was triggered. The best 35 m time, and all associated split times were kept for analysis.

Below is the mixed-effects models analysis of the dataset. 

```{r}
data("vescovi")

# Convert data to long
df <- vescovi %>%
  select(1:13) %>%
  # slice(1:10) %>%
  pivot_longer(
    cols = 9:13,
    names_to = "distance",
    values_to = "time"
  ) %>%
  mutate(
    distance = as.numeric(str_extract(distance, "^[0-9]+"))
  )
```

The following models were used: (1) no corrections model, (2) fixed time correction model (using +0.3s heuristic rule of thumb), (3) time correction model with time correction as fixed effect, (4) time correction model with time correction as random effect, (5) distance correction model with distance correction as fixed effect, (6) distance correction model with distance correction as random effect, (7) time and distance correction model, (8) time and distance correction model with distance correction as fixed effect (and time correction as random effect), and (9) time and distance correction model with distance and time correction as random effects (please refer to the [Supplemental material] for the R code). 

```{r echo=FALSE}
no_corrections <- mixed_model_using_splits(
  df,
  distance = "distance",
  time = "time",
  athlete = "Athlete"
)

fixed_correction <- mixed_model_using_splits(
  df,
  distance = "distance",
  time = "time",
  athlete = "Athlete",
  time_correction = 0.3
)

time_correction_fixed <-
  mixed_model_using_splits_with_time_correction(
    df,
    distance = "distance",
    time = "time",
    athlete = "Athlete",
    random = MSS + TAU ~ 1
  )

time_correction_random <-
  mixed_model_using_splits_with_time_correction(
    df,
    distance = "distance",
    time = "time",
    athlete = "Athlete",
    random = MSS + TAU + time_correction ~ 1
  )

distance_correction_fixed <-
  mixed_model_using_splits_with_distance_correction(
    df,
    distance = "distance",
    time = "time",
    athlete = "Athlete",
    random = MSS + TAU ~ 1
  )

distance_correction_random <-
  mixed_model_using_splits_with_distance_correction(
    df,
    distance = "distance",
    time = "time",
    athlete = "Athlete",
    random = MSS + TAU + distance_correction ~ 1, 
    control = nlme::nlmeControl(tolerance = 0.01)
  )

time_distance_correction_fixed <-
  mixed_model_using_splits_with_corrections(
    df,
    distance = "distance",
    time = "time",
    athlete = "Athlete",
    random = MSS + TAU ~ 1
  )

time_distance_correction_time_random <-
  mixed_model_using_splits_with_corrections(
    df,
    distance = "distance",
    time = "time",
    athlete = "Athlete",
    random = MSS + TAU + time_correction ~ 1
  )

time_distance_correction_random <-
  mixed_model_using_splits_with_corrections(
    df,
    distance = "distance",
    time = "time",
    athlete = "Athlete",
    random = MSS + TAU + time_correction + distance_correction ~ 1
  )
```

The following image represents model fit estimator RSE for each model. As can be seen, RSE is reduced the more flexible the model. 

```{r echo=FALSE}
model_fit <- rbind(
  data.frame(
    model = "No corrections",
    t(unlist(no_corrections$model_fit))
  ),
  data.frame(
    model = "Fixed correction +0.3s",
    t(unlist(fixed_correction$model_fit))
  ),
  data.frame(
    model = "Time correction fixed",
    t(unlist(time_correction_fixed$model_fit))
  ),
  data.frame(
    model = "Time correction random",
    t(unlist(time_correction_random$model_fit))
  ),
  data.frame(
    model = "Distance correction fixed",
    t(unlist(distance_correction_fixed$model_fit))
  ),
  data.frame(
    model = "Distance correction random",
    t(unlist(distance_correction_random$model_fit))
  ),
  data.frame(
    model = "Time and distance correction fixed",
    t(unlist(time_distance_correction_fixed$model_fit))
  ),
  data.frame(
    model = "Time and distance correction (time correction random)",
    t(unlist(time_distance_correction_time_random$model_fit))
  ),
  data.frame(
    model = "Time and distance correction random",
    t(unlist(time_distance_correction_random$model_fit))
  )
)

model_fit$model <- factor(
  model_fit$model,
  levels = rev(c(
    "No corrections",
    "Fixed correction +0.3s",
    "Time correction fixed",
    "Time correction random",
    "Distance correction fixed",
    "Distance correction random",
    "Time and distance correction fixed",
    "Time and distance correction (time correction random)",
    "Time and distance correction random"
  ))
)

ggplot(model_fit, aes(x = RSE, y = model)) +
  theme_bw(8) +
  geom_point() +
  xlab("RSE (s)") +
  ylab(NULL)
```

The following image depicts estimated parameters for each model:

```{r echo=FALSE}
est_params <- rbind(
  data.frame(
    model = "No corrections",
    no_corrections$parameters$random
  ),
  data.frame(
    model = "Fixed correction +0.3s",
    fixed_correction$parameters$random
  ),
  data.frame(
    model = "Time correction fixed",
    time_correction_fixed$parameters$random
  ),
  data.frame(
    model = "Time correction random",
    time_correction_random$parameters$random
  ),
  data.frame(
    model = "Distance correction fixed",
    distance_correction_fixed$parameters$random
  ),
  data.frame(
    model = "Distance correction random",
    distance_correction_random$parameters$random
  ),
  data.frame(
    model = "Time and distance correction fixed",
    time_distance_correction_fixed$parameters$random
  ),
  data.frame(
    model = "Time and distance correction (time correction random)",
    time_distance_correction_time_random$parameters$random
  ),
  data.frame(
    model = "Time and distance correction random",
    time_distance_correction_random$parameters$random
  )
)

est_params$model <- factor(
  est_params$model,
  levels = rev(c(
    "No corrections",
    "Fixed correction +0.3s",
    "Time correction fixed",
    "Time correction random",
    "Distance correction fixed",
    "Distance correction random",
    "Time and distance correction fixed",
    "Time and distance correction (time correction random)",
    "Time and distance correction random"
  ))
)

est_params <- est_params %>%
  pivot_longer(cols = -(1:2), names_to = "parameter")

est_params$parameter <- factor(
  est_params$parameter,
  levels = c(
    "MSS",
    "TAU",
    "MAC",
    "PMAX",
    "time_correction",
    "distance_correction"
  )
)

ggplot(est_params, aes(y = model, x = value)) +
  theme_bw(8) +
  geom_boxplot() +
  facet_wrap(~parameter, scales = "free_x") +
  xlab(NULL) +
  ylab(NULL)
```

The following image depicts model residuals across distance splits. To provide practical magnitude of the residuals, we have used between subject observed time SD multiplied with 0.2 and -0.2. This provides practical anchor for the residual magnitude, often referred to as *smallest worthwhile change* (SWC) or *smallest effect size of interest* (SESOI) [@jovanovicBmbstatsBootstrapMagnitudebased2020]. If the residuals are within this magnitude band, then the model is good in making practically useful predictions.  Error bars represent residual bias $\pm$ 1 SD. 

```{r echo=FALSE}
model_resid <- rbind(
  data.frame(
    model = "No corrections",
    no_corrections$data
  ),
  data.frame(
    model = "Fixed correction +0.3s",
    fixed_correction$data
  ),
  data.frame(
    model = "Time correction fixed",
    time_correction_fixed$data
  ),
  data.frame(
    model = "Time correction random",
    time_correction_random$data
  ),
  data.frame(
    model = "Time and distance correction fixed",
    time_distance_correction_fixed$data
  ),
  data.frame(
    model = "Time and distance correction (time correction random)",
    time_distance_correction_time_random$data
  ),
  data.frame(
    model = "Time and distance correction random",
    time_distance_correction_random$data
  )
)


model_resid$model <- factor(
  model_resid$model,
  levels = rev(c(
    "No corrections",
    "Fixed correction +0.3s",
    "Time correction fixed",
    "Time correction random",
    "Time and distance correction fixed",
    "Time and distance correction (time correction random)",
    "Time and distance correction random"
  ))
)

model_resid$resid <- model_resid$time - model_resid$pred_time

# Create SWC / SESOI band
model_SESOI <- model_resid %>%
  group_by(model, distance) %>%
  summarise(
    bias = mean(resid),
    variance = sd(resid),
    upper = bias + variance,
    lower = bias - variance,
    MAD = mean(abs(resid)),
    SESOI_upper = sd(time) * 0.2,
    SESOI_lower = -sd(time) * 0.2
  )

# Plot
ggplot(model_resid, aes(y = model)) +
  theme_bw(8) +
  geom_vline(
    data = model_SESOI,
    aes(xintercept = SESOI_lower),
    color = "blue", alpha = 0.5, linetype = "dashed"
  ) +
  geom_vline(
    data = model_SESOI,
    aes(xintercept = SESOI_upper),
    color = "blue", alpha = 0.5, linetype = "dashed"
  ) +
  geom_vline(xintercept = 0, color = "blue", alpha = 0.5) +
  geom_jitter(aes(x = resid), alpha = 0.1, height = 0.25) +
  geom_errorbarh(
    data = model_SESOI,
    aes(xmin = lower, xmax = upper),
    height = 0.1, color = "black"
  ) +
  geom_point(data = model_SESOI, aes(x = bias), color = "black") +
  facet_wrap(~distance, scales = "free_x") +
  xlab("Observed time - predicted time (s)") +
  ylab(NULL)
```

The following figure depicts model residuals estimators (bias, or mean residual; variance, or SD of the residuals, and MAD, or mean absolute difference). 

```{r echo=FALSE}
df <- model_SESOI %>%
  pivot_longer(cols = -(1:2), names_to = "estimator") %>%
  filter(estimator %in% c("bias", "variance", "MAD"))

df$model <- factor(
  df$model,
  levels = rev(c(
    "No corrections",
    "Fixed correction +0.3s",
    "Time correction fixed",
    "Time correction random",
    "Time and distance correction fixed",
    "Time and distance correction (time correction random)",
    "Time and distance correction random"
  ))
)

df$estimator <- factor(
  df$estimator,
  levels = c("bias", "variance", "MAD")
)

ggplot(df, aes(x = value, y = model)) +
  theme_bw(8) +
  geom_point() +
  facet_grid(distance ~ estimator, scales = "free_x") +
  xlab(NULL) +
  ylab(NULL)
```

Which model should be used? Although providing a better fit (using RSE as an estimator of model fit), the time and distance correction models often estimate these parameters that are harder to interpret (e.g., negative distance correction). Although providing novel theoretical models in this paper, we acknowledge the need for validating them in practice, against gold-standard methods, assessing their agreement, as well as their power in detecting and adjusting for timing inconsistencies. More thorough theoretical simulation study is currently in development with the aim to explore the behavior of these models under different scenarios. 

We are hoping that the **shorts** package will help fellow sports scientists and coaches in exploring short sprint profiles and help in driving research, particularly in devising measuring protocols that are sensitive enough to capture training intervention changes, but also robust enough to take into account potential sprint initiation and timing inconsistencies.  
```{r include=FALSE}
# Return original options
options(op)
```

# Supplemental material

The *R Markdown* [@R-bookdown; @R-rmarkdown; @rmarkdown2018; @rmarkdown2020] source code for the paper can be found on the GitHub repository: [https://github.com/mladenjovanovic/shorts-paper](https://github.com/mladenjovanovic/shorts-paper). 

# References
